{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a6809d",
   "metadata": {},
   "source": [
    "Aim: To implement and train memory augmented neural networks, a black-box meta-learner that uses a recurrent neural network for few shot classification.\n",
    "\n",
    "Pravalika Arunkumar \n",
    "B.Tech AI & DS - B\n",
    "21011101089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389274be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Load data from the config file\n",
    "with open(\"config.json\") as json_data_file:\n",
    "    data = json.load(json_data_file)\n",
    "\n",
    "k_shot = data[\"k_shot\"]\n",
    "n_way = data[\"n_way\"]\n",
    "batch_size = data[\"batch_size\"]\n",
    "size = data[\"img_size\"]\n",
    "epochs = data[\"epochs\"]\n",
    "train_parent_folder = data[\"train_parent_folder\"]\n",
    "test_test_folder = data[\"test_parent_folder\"]\n",
    "bi_dir = data[\"bi_dir\"]\n",
    "\n",
    "print('A', k_shot, 'Shot', n_way, 'Way classification')\n",
    "\n",
    "def get_all_paths(why = 'train'):\n",
    "    \"\"\"\n",
    "    Returns a list of all the train/test character folder paths\n",
    "    Args: \n",
    "        why: 'test' or 'train' (default = 'train)\n",
    "    Returns:\n",
    "        A list of all characters' path \n",
    "    \"\"\"\n",
    "    if why == 'train':\n",
    "        parent_folder = train_parent_folder\n",
    "    if why == 'test':\n",
    "        parent_folder = test_test_folder\n",
    "    sub_folders = glob.glob(parent_folder) # Directories of all languages\n",
    "    image_paths = [glob.glob(sub_folder + '\\*') for sub_folder in sub_folders] # Directories of all characters\n",
    "    image_paths = sum(image_paths, []) # Flatten out the 2D list to a 1D list \n",
    "    return image_paths\n",
    "\n",
    "def get_image_path_label(all_paths):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples of image path and it's class\n",
    "    Args: \n",
    "        all_paths: A list of all characters' path \n",
    "    Returns:\n",
    "        A list of (k+1 * n) images' path \n",
    "    \"\"\"\n",
    "    n_folders_int  = random.sample(range(0, len(all_paths)), n_way)\n",
    "    image_labels = [[(glob.glob(all_paths[n] + '\\*')[k], n) # (path, label)\n",
    "                    for n in n_folders_int\n",
    "                    for k in random.sample(range(0, len(glob.glob(all_paths[n] + '\\*'))), k_shot+1)\n",
    "                    ] for b in range(batch_size)] \n",
    "    return image_labels\n",
    "\n",
    "def batch_data(why = 'train'):\n",
    "    \"\"\"\n",
    "    Returns the data required to train / test the modelZ\n",
    "    Args: \n",
    "        why: 'test' or 'train' (default = 'train)\n",
    "    Returns:\n",
    "        total_list: A list of input image batches of shape [Batch_size, (K_shot + 1) * N_way, img_shape**2 + N_way]\n",
    "        true_labels: A list of target label batches of shape [Batch_size, (K_shot + 1) * N_way, 1]\n",
    "    \"\"\"\n",
    "    if why == 'train':\n",
    "        all_paths = all_train_paths\n",
    "    if why == 'test':\n",
    "        all_paths = all_test_paths\n",
    "    paths_labels = get_image_path_label(all_paths)\n",
    "    keys = set([path_label[1] for path_label in paths_labels[0]])\n",
    "    values = [i for i in range(len(keys))]\n",
    "    label_dict = dict(zip(keys, values))\n",
    "    total_list = []\n",
    "    true_labels = []\n",
    "    for b in range(batch_size):\n",
    "        dummy_first_set = []\n",
    "        dummy_second_set = []\n",
    "        dummy_true_labels = []\n",
    "        for samp_no, path_label in enumerate(paths_labels[b]):\n",
    "            path = path_label[0]\n",
    "            label = path_label[1]\n",
    "            img = Image.open(path)\n",
    "            img = img.resize((size, size))\n",
    "            img = np.array(img).flatten()/ 255.0\n",
    "            feat_label = torch.zeros([n_way])\n",
    "            feat_label[label_dict[label]] = 1\n",
    "            if samp_no % (k_shot + 1) == 0:\n",
    "                feature = np.concatenate((img,torch.zeros([n_way])))\n",
    "                dummy_second_set.append(feature)\n",
    "                dummy_true_labels.append(label_dict[label])\n",
    "            else:\n",
    "                feature = np.concatenate((img, feat_label))\n",
    "                dummy_first_set.append(feature)\n",
    "        \n",
    "        dummy_total_list = np.concatenate((dummy_first_set, dummy_second_set))\n",
    "        total_list.append(torch.tensor(dummy_total_list))\n",
    "        true_labels.append(torch.tensor(dummy_true_labels))\n",
    "\n",
    "    total_list = torch.stack(total_list).float()\n",
    "    true_labels = torch.stack(true_labels).float()\n",
    "    return total_list, true_labels\n",
    "\n",
    "class Omniglot_MANN(nn.Module):\n",
    "    def __init__(self, k_shot, n_way, batch_size, img_size):\n",
    "        super(Omniglot_MANN, self).__init__()\n",
    "        global bi_dir\n",
    "        n = 1\n",
    "        if bi_dir:\n",
    "            n = 2\n",
    "        self.k_shot = k_shot\n",
    "        self.n_way = n_way\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.lstm1 = nn.LSTM(img_size + n_way, 128, batch_first = True, bidirectional = bi_dir)\n",
    "        self.lstm2 = nn.LSTM(128*n, n_way, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1,_ = self.lstm1(x)\n",
    "        x2,_ = self.lstm2(x1)\n",
    "        return x2[:,-self.n_way:]\n",
    "\n",
    "def get_acc(pred, truth):\n",
    "    \"\"\"\n",
    "    Returns the accuracy of the prediction\n",
    "    Args: \n",
    "        pred: A 2D array of predicted values of shape [Batch_size, N_shot]\n",
    "        truth: A 2D array of target values of shape [Batch_size, N_shot]\n",
    "    Returns:\n",
    "        A scalar value\n",
    "    \"\"\"\n",
    "    acc_sum = 0\n",
    "    for i in range(len(pred)):\n",
    "        for p, t in zip(pred[i], truth[i]):\n",
    "            if torch.argmax(p) == t:\n",
    "                acc_sum += 1\n",
    "            # print(torch.argmax(p))\n",
    "    return acc_sum\n",
    "\n",
    "model = Omniglot_MANN(k_shot = k_shot, n_way = n_way, batch_size = batch_size, img_size = size**2)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "all_train_paths = get_all_paths('train')\n",
    "all_test_paths = get_all_paths('test')\n",
    "\n",
    "all_loss = []\n",
    "\n",
    "print('Starting training...')\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Train the model\n",
    "    optimizer.zero_grad()\n",
    "    X, Y = batch_data('train')\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y.long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (e+1) % 100 == 0: \n",
    "        # Test the model\n",
    "        X, Y = batch_data('test')\n",
    "        pred = model(X)\n",
    "        val_loss = criterion(pred, Y.long())\n",
    "        accuracy = ((get_acc(pred, Y))/(batch_size * n_way))*100\n",
    "        all_loss.append(val_loss.item())\n",
    "\n",
    "        print('Epoch:', e + 1, '; Loss:', val_loss.item(), '; Acc:', accuracy)\n",
    "\n",
    "print('Completed Training!')\n",
    "# To save the training loss curve\n",
    "plt.plot(all_loss)\n",
    "plt.title( str(k_shot) + ' shot ' +  str(n_way) + ' way -  ' + ' Test performance')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.savefig('loss_curve.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
